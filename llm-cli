from dotenv import load_dotenv
import requests
import json
import os

load_dotenv()


API_KEY = os.environ.get("OPENROUTER_API_KEY")
MODEL_NAME = "deepseek/deepseek-r1:free"  # Replace with the model name you wish to use

# Function to interact with the API
def ask_question(question: str):
    # Append user input to conversation history
    conversation_history.append({"role": "user", "content": question})
    
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": MODEL_NAME,
        "messages": conversation_history,
        "stream": True
    }
    
    # Clean, simple output format
    print(f"\n{MODEL_NAME}:")
    
    # This will store the complete assistant response
    full_response = ""
    
    try:
        with requests.post(url, headers=headers, json=payload, stream=True) as response:
            response.raise_for_status()  # Raise exception for bad status codes
            
            buffer = ""
            for chunk in response.iter_lines(decode_unicode=True):
                if not chunk:
                    continue
                    
                if chunk.startswith('data: '):
                    data = chunk[6:]
                    if data == '[DONE]':
                        break
                        
                    try:
                        data_obj = json.loads(data)
                        content = data_obj["choices"][0]["delta"].get("content", "")
                        if content:
                            print(content, end="", flush=True)  # Print incrementally without newlines
                            full_response += content
                    except json.JSONDecodeError:
                        pass
                        
        print("\n")  # Add a newline after the full response
        
        # Only add to conversation history after receiving the complete response
        if full_response:
            conversation_history.append({"role": "assistant", "content": full_response})
            
    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")

# Main loop for continuous interaction
def start_conversation():
    print(f"Starting conversation with {MODEL_NAME}. Type 'exit' to end.")
    print("-----------------------------------------------------------")
    while True:
        # Clean, simple prompt with no redundant output
        user_input = input("\nYou: ")
        if user_input.lower() == "exit":
            print("Conversation ended.")
            break
        ask_question(user_input)

# Start the conversation
if __name__ == "__main__":
    conversation_history = []
    start_conversation()